{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import time\n",
    "import smtplib, ssl\n",
    "import random\n",
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "import webbrowser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send mail code\n",
    "\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "port = 587  # For starttls\n",
    "sender_email = \"facerecognitionnitk@gmail.com\"\n",
    "#password = input(\"Type your password and press enter: \")\n",
    "password = \"facerecognition@1234\"\n",
    "receiver_email = \"mathurshipra33@gmail.com\"\n",
    "\n",
    "\n",
    "# Try to log in to server and send email\n",
    "message = \"\"\"\\\n",
    "Subject:{}\n",
    "\n",
    "Do you want to admit {}?.\n",
    "\"\"\"\n",
    "def send(person):\n",
    "    message1=message.format(random.randint(1,1000),person)\n",
    "    \n",
    "    # Create a secure SSL context\n",
    "    context = ssl.create_default_context()\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server,port)\n",
    "        server.ehlo() # Can be omitted\n",
    "        server.starttls(context=context) # Secure the connection\n",
    "        server.ehlo() # Can be omitted\n",
    "        server.login(sender_email, password)\n",
    "\n",
    "        server.sendmail(sender_email, receiver_email, message1)\n",
    "        # TODO: Send email here\n",
    "    except Exception as e:\n",
    "        # Print any error messages to stdout\n",
    "        print(e)\n",
    "    finally:\n",
    "        server.quit() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#receive email block\n",
    "\n",
    "def receive():\n",
    "    \n",
    "    # account credentials\n",
    "    username = \"facerecognitionnitk@gmail.com\"\n",
    "    password = \"facerecognition@1234\"\n",
    "    # create an IMAP4 class with SSL \n",
    "    imap = imaplib.IMAP4_SSL(\"imap.gmail.com\")\n",
    "    # authenticate\n",
    "    imap.login(username, password)\n",
    "\n",
    "    status, messages = imap.select(\"INBOX\")\n",
    "    # number of top emails to fetch\n",
    "    N = 1\n",
    "    # total number of emails\n",
    "    messages = int(messages[0])\n",
    "\n",
    "    for i in range(messages, messages-N, -1):\n",
    "        # fetch the email message by ID\n",
    "        res, msg = imap.fetch(str(i), \"(RFC822)\")\n",
    "        for response in msg:\n",
    "            if isinstance(response, tuple):\n",
    "                # parse a bytes email into a message object\n",
    "                msg = email.message_from_bytes(response[1])\n",
    "                # decode the email subject\n",
    "                subject = decode_header(msg[\"Subject\"])[0][0]\n",
    "                if isinstance(subject, bytes):\n",
    "                    # if it's a bytes, decode to str\n",
    "                    subject = subject.decode()\n",
    "                # email sender\n",
    "                from_ = msg.get(\"From\")\n",
    "                # if the email message is multipart\n",
    "                if msg.is_multipart():\n",
    "                    # iterate over email parts\n",
    "                    for part in msg.walk():\n",
    "                        content_type = part.get_content_type()\n",
    "                        content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "                        try:\n",
    "                            body1 = part.get_payload(decode=True).decode()\n",
    "                        except:\n",
    "                            pass\n",
    "                        if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
    "                            break\n",
    "    imap.close()\n",
    "    imap.logout()\n",
    "\n",
    "    body1 = str(body1).split('.')\n",
    "    #print(body1)\n",
    "    if body1[1] == 'dir=\"auto\">Yes</div>' or body1[0] == 'Yes\\n' or body1[0] == 'Yes' or body1[0] == 'yes' or body1[0] == 'yes\\n':\n",
    "        return \"Person Admitted\"\n",
    "    else:\n",
    "        return (\"Person Not Admitted. Access Denied\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we make a list of the images we have and write a function that automatically gets the images and generates encodings for the face\n",
    "\n",
    "path='SMARTLOCK' # Specifying the path from where to fetch the images inside the computer memory\n",
    "Images=[]\n",
    "Names=[]     #creating a list for images and their names,we fetch the names from the image name itself and do not hard code them separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'DarpitaMathur', 'KapilMathur', 'KusumMathur', 'NainaMathur', 'ShipraMathur']\n"
     ]
    }
   ],
   "source": [
    "myList=os.listdir(path)     # Assigning the path to fetch the images \n",
    "for ppl in myList:\n",
    "    current=cv2.imread(f'{path}/{ppl}')    # Reading the image in the path\n",
    "    Images.append(current)\n",
    "    Names.append(os.path.splitext(ppl)[0]) # Assigning the names and appending them to the names list \n",
    "print(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-tswt8jna\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5c07aafcd8b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEncodedList\u001b[0m  \u001b[1;31m#return the list storing the encodings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mEncodeKnownFaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEncod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-5c07aafcd8b5>\u001b[0m in \u001b[0;36mEncod\u001b[1;34m(Images)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mEncodedList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m      \u001b[1;31m# List that will store all the encodings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m#Image obtained initially is in BGR format,first we convert it into RGB format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Encoding is found for each image in the list one by one and appended into the EncodedList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mEncodedList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-tswt8jna\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# After loading the images,we need to find their encodings one by one ,for this we make a function\n",
    "\n",
    "def Encod(Images):      # Passing the list of Images as parameter for finding encodings function\n",
    "    EncodedList=[]      # List that will store all the encodings \n",
    "    for img in Images:\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)      #Image obtained initially is in BGR format,first we convert it into RGB format\n",
    "        encoding=face_recognition.face_encodings(img)[0] # Encoding is found for each image in the list one by one and appended into the EncodedList\n",
    "        EncodedList.append(encoding)\n",
    "\n",
    "    return EncodedList  #return the list storing the encodings \n",
    "EncodeKnownFaces=Encod(Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-tswt8jna\\opencv\\modules\\highgui\\src\\window.cpp:651: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3a547349c7ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m    \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image captured'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Displaying the image captured via webcam to the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m    \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-tswt8jna\\opencv\\modules\\highgui\\src\\window.cpp:651: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    " # The image to be comapred and recognised comes from the web cam connected,hence initialising the web cam using cv2\n",
    "imgCapture=cv2.VideoCapture(0)  \n",
    "\n",
    "while True:\n",
    "    success, img=imgCapture.read()  # Reading and storing the images captured through webcam\n",
    "    CompressImg=cv2.resize(img,(0,0),None,0.25,0.25)   #compressing the image to one fourth size \n",
    "    CompressImg = cv2.cvtColor(CompressImg,cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    faceloc=face_recognition.face_locations(CompressImg)    # From the whole image,locating the face first \n",
    "    encodings=face_recognition.face_encodings(CompressImg,faceloc)   # Finding the encoding of each face captured through web cam in the compressed image\n",
    "\n",
    "    for encodeface,facelocations in zip(encodings,faceloc):\n",
    "        match=face_recognition.compare_faces(EncodeKnownFaces,encodeface) # comparing the face obtained from web cam with each face stored in the known list of faces to find if the person appearing at the doorstep is a known person or not\n",
    "        facedis=face_recognition.face_distance(EncodeKnownFaces,encodeface)# Finds the distance/difference in values of the encoding of the image captured and the images present in the known list\n",
    "\n",
    "        Index=np.argmin(facedis)  #This index refers to the index of the image from the list of images that we would take as reference which corressponds to the image having minimum difference in encoding values\n",
    "\n",
    "        if match[Index]:   #now we check if on matching the obtained image from the reference image,we get true or not\n",
    "            name=Names[Index]  # Assigning the name to be printed in case the face is recognised.Names were stored in the Names list\n",
    "            y1,x2,y2,x1=facelocations\n",
    "            y1,x2,y2,x1=y1*4,x2*4,y2*4,x1*4\n",
    "        # Above code multiplies the co-ordinates of the locations obtained by 4 because earlier the compression has reduced the image size to 1/4 the size,hence regaining the original co-ordinates\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2) #this draws a rectangle around the face in the captured image using the faceloc variable that has stored the co-ordinates of the location of the face\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)# printing the name onto the image according to the required postion,font and colour\n",
    "            send(name)\n",
    "            status=\" \"\n",
    "            while status==\" \":\n",
    "                status=receive()\n",
    "            print(status)\n",
    "    \n",
    "    \n",
    "        else:\n",
    "            text=\"Intruder/Unknown\"\n",
    "            y1,x2,y2,x1=facelocations\n",
    "            y1,x2,y2,x1=y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "            cv2.putText(img,text,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2) #cv2.putText() method is used to draw a text string on any image.\n",
    "            send(\"imposter\")\n",
    "            status=\" \"\n",
    "            while status==\" \":\n",
    "                status=receive()\n",
    "            print(status)\n",
    "    \n",
    "\n",
    "    cv2.imshow('Image captured',img) #Displaying the image captured via webcam to the user\n",
    "    cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
